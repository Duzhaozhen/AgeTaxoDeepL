{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02b539a9-681e-4bc9-be6b-11179eaeaea7",
   "metadata": {},
   "source": [
    "# MixResNet18 Model Tranining Script\n",
    "### This Notebook is used to train ResNet18 model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc36a50-cf92-44fa-9ed4-37f0ce5b2c8d",
   "metadata": {},
   "source": [
    "#### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed9739cf-a896-4b92-9897-d865724af602",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torchvision.transforms import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from time import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5429ec-dcc8-4b1a-a152-9fd9dcd903bc",
   "metadata": {},
   "source": [
    "\n",
    "#### 1. Global Settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b03cc36-896e-4577-9b58-6a3aaa0f81e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "BATCH_SIZE = 128\n",
    "EPOCH = 500\n",
    "NUM_CLASSES = 10\n",
    "RANDOM_SEED = 42\n",
    "EARLY_STOPPING_PATIENCE = 30\n",
    "EARLY_STOPPING_DELTA = 0.0001\n",
    "SHOW_TRAINING_PROCESS = False #Whether to display the training process\n",
    "\n",
    "# Path settings\n",
    "ROOT_DIR = \"/path/to/your/data/folder\" \n",
    "TRAIN_CSV_PATH = os.path.join(ROOT_DIR, \"meta/training_info.csv\") # There are two columns, the first is Path and the second is label\n",
    "VAL_CSV_PATH = os.path.join(ROOT_DIR, \"meta/val_info.csv\") # There are two columns, the first is Path and the second is label\n",
    "\n",
    "# Path for saving the best model and the results CSV\n",
    "RESULTS_DIR = \"/path/to/your/results/folder\" ### Paths where training set files and validation set files and their images are stored\n",
    "MODEL_SAVE_PATH = os.path.join(RESULTS_DIR, \"MixResNet18_best_model.pth\") # model file\n",
    "STATS_SAVE_PATH = os.path.join(RESULTS_DIR, \"MixResNet18_normalization_stats.json\") # mean and std\n",
    "CSV_SAVE_PATH = os.path.join(RESULTS_DIR, \"MixResNet18_training_log.csv\") ## Training logs with the loss and accuracy of the training and test sets in each epoch\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True) # Ensure the results directory exists\n",
    "\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "\n",
    "# Label and class mapping\n",
    "CUSTOM_LABEL_MAPPING =  {'UniStable': 0, 'UniUnstable': 1,'LinAgeHomo': 2, 'LinAgeHet': 3,'NonAgeHet': 4,\n",
    "                        'Outlier': 5,'TriAge': 6,'TriNonAge': 7,'BiAge':8, 'BiNonAge': 9}\n",
    "\n",
    "CLASSES = tuple(CUSTOM_LABEL_MAPPING.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a762a8c-7279-48cd-8d4f-3b6e19568317",
   "metadata": {},
   "source": [
    "### 2.Dataset Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b99c5929-acc4-4a04-8f1d-ffc25cc4bc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CpGImageDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Loads image paths and labels from a CSV file and creates a dataset.\n",
    "    \"\"\"\n",
    "    def __init__(self, root_dir, path_csv, label_mapping, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.path_csv = path_csv\n",
    "        self.transform = transform\n",
    "        self.label_mapping = label_mapping\n",
    "        self.img_info = [] # [(path, label), ... , ]\n",
    "        self._get_img_info()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path_img, label = self.img_info[index]\n",
    "        img = Image.open(path_img).convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        if len(self.img_info) == 0:\n",
    "            raise Exception(f\"\\ndata_dir:{self.root_dir} is an empty dir! Please check your path to images!\")\n",
    "        return len(self.img_info)\n",
    "\n",
    "    def _get_img_info(self):\n",
    "        \"\"\"\n",
    "        Reads the CSV file and parses image paths and labels.\n",
    "        \"\"\"\n",
    "        column_names = [\"Path\",\"Label\"]\n",
    "        df = pd.read_csv(self.path_csv,\n",
    "                header=None,\n",
    "                index_col=False,\n",
    "                names=column_names,\n",
    "                sep=\",\"\n",
    "                )\n",
    "        df.reset_index(inplace=True)\n",
    "\n",
    "        for idx in range(len(df)):\n",
    "            path_img = os.path.join(self.root_dir, df.loc[idx, \"Path\"])\n",
    "            label_str = df.at[idx,\"Label\"]\n",
    "            if label_str in self.label_mapping:\n",
    "                label_int = self.label_mapping[label_str]\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown label on line {idx}: {label_str}\")\n",
    "            self.img_info.append((path_img, label_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533901ff-c3fe-41ea-b482-bbbb60dee3f3",
   "metadata": {},
   "source": [
    "### 3. Calculate Mean and Std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c0f5725-4abe-4e00-ab0a-3cae0520a31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing mean and variance for training data...\n",
      "Calculated Mean: [np.float32(0.8675819), np.float32(0.99111927), np.float32(0.8675819)]\n",
      "Calculated Std: [np.float32(0.3242125), np.float32(0.03585337), np.float32(0.3242125)]\n",
      "Saving normalization stats...\n",
      "Stats saved to: ~/model/MixResNet18_normalization_stats.json\n"
     ]
    }
   ],
   "source": [
    "def get_stat(dataset):\n",
    "    \"\"\"\n",
    "    Computes the mean and standard deviation per channel for the dataset.\n",
    "    :param dataset: A PyTorch Dataset object.\n",
    "    :return: (mean, std)\n",
    "    \"\"\"\n",
    "    print('Computing mean and variance for training data...')\n",
    "    loader = DataLoader(dataset, batch_size=1, shuffle=False, pin_memory=True, num_workers=4)\n",
    "    \n",
    "    mean = torch.zeros(3)\n",
    "    std = torch.zeros(3)\n",
    "    for x, _ in loader:\n",
    "        for d in range(3):\n",
    "            mean[d] += x[:, d, :, :].mean()\n",
    "            std[d] += x[:, d, :, :].std()\n",
    "    mean.div_(len(dataset))\n",
    "    std.div_(len(dataset))\n",
    "    return list(mean.numpy()), list(std.numpy())\n",
    "\n",
    "# Step 3.1: Create a temporary dataset with only ToTensor transformation to calculate stats\n",
    "temp_transform = transforms.Compose([transforms.ToTensor()])\n",
    "stat_dataset = CpGImageDataset(ROOT_DIR, TRAIN_CSV_PATH, CUSTOM_LABEL_MAPPING, transform=temp_transform)\n",
    "# Step 3.2: Calculate the mean and std\n",
    "mean, std = get_stat(stat_dataset)\n",
    "print(f\"Calculated Mean: {mean}\")\n",
    "print(f\"Calculated Std: {std}\")\n",
    "\n",
    "print(\"Saving normalization stats...\")\n",
    "norm_stats = {\n",
    "    'mean': [float(x) for x in mean],\n",
    "    'std': [float(x) for x in std]\n",
    "}\n",
    "with open(STATS_SAVE_PATH, 'w') as f:\n",
    "    json.dump(norm_stats, f, indent=4)\n",
    "#print(f\"Stats saved to: {STATS_SAVE_PATH}\")\n",
    "print(f\"Stats saved to: ~/model/MixResNet18_normalization_stats.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7af7758-b5d9-4e5c-baab-aa425ec90dcb",
   "metadata": {},
   "source": [
    "### 4. Data Preprocessing and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7eae54b-9ed3-45f1-a453-85e0f894daee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 18000\n",
      "Number of validation samples: 2000\n"
     ]
    }
   ],
   "source": [
    "# Define data transformations using the calculated mean and std\n",
    "data_transform = {\n",
    "    \"train\": transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ]),\n",
    "    \"val\": transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Create the final training and validation datasets\n",
    "train_data = CpGImageDataset(ROOT_DIR, TRAIN_CSV_PATH, CUSTOM_LABEL_MAPPING, transform=data_transform[\"train\"])\n",
    "val_data = CpGImageDataset(ROOT_DIR, VAL_CSV_PATH, CUSTOM_LABEL_MAPPING, transform=data_transform[\"val\"])\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "val_dataloader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "\n",
    "print(f\"Number of training samples: {len(train_data)}\")\n",
    "print(f\"Number of validation samples: {len(val_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387084d9-829d-4455-932f-3e5b565a5e54",
   "metadata": {},
   "source": [
    " \n",
    "### 5. Model Definition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9b4b8a2-a024-4da4-9e2f-b81f6f644cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ResNet18(num_classes):\n",
    "    \"\"\"\n",
    "    Loads the ResNet18 model and adapts its fully connected layer\n",
    "    to the specified number of classes.\n",
    "    \"\"\"\n",
    "    res18 = models.resnet18(weights=None) # Train from scratch, not using pre-trained weights\n",
    "    num_ftrs = res18.fc.in_features\n",
    "    res18.fc = nn.Linear(num_ftrs, num_classes)\n",
    "    return res18\n",
    "\n",
    "# Instantiate the model and move it to the specified device\n",
    "model = ResNet18(num_classes=NUM_CLASSES).to(device)\n",
    "\n",
    "# Define optimizer with weight decay\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.1, patience=3)\n",
    "loss_function = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d9b8b2-8fa5-4c49-8a7a-8413dcf7faae",
   "metadata": {},
   "source": [
    "\n",
    "### 6. Evaluation Function and Early Stopping Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91f1633c-8698-47dd-a20a-53e16c6b784f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def evaluate(model, data_loader, loss_fn, device):\n",
    "    \"\"\"Evaluates the model on a given dataset.\"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():  # No need to track gradients for evaluation\n",
    "        for images, labels in data_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            prediction = outputs.argmax(dim=1)\n",
    "            correct_predictions += torch.eq(prediction, labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "\n",
    "    accuracy = correct_predictions / total_samples\n",
    "    return accuracy, avg_loss\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation accuracy doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, save_path, patience=7, verbose=False, delta=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            save_path (str):  Path for saving the best model.ã€‚\n",
    "            patience (int): How long to wait after last time validation accuracy improved.\n",
    "            verbose (bool):  If True, prints a message for each validation accuracy improvement.\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "        \"\"\"\n",
    "        self.save_path = save_path\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_acc_max = float('-inf')\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_acc, model):\n",
    "        score = val_acc\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_acc, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_acc, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_acc, model):\n",
    "        '''When the accuracy of the validation set improves, save the model'''\n",
    "        if self.verbose:\n",
    "            print(f'Validation accuracy increased ({self.val_acc_max:.6f} --> {val_acc:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.save_path)\n",
    "        self.val_acc_max = val_acc\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61627e7-0103-4cdd-b203-c29688f7191d",
   "metadata": {},
   "source": [
    "### 7. Training and Validation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6405d210-dabe-4ba2-99c5-a9fb59c250df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Early stopping triggered\n",
      "\n",
      "--- Training Finished! ---\n",
      "Total training time: 35.18 minutes\n",
      "Best model saved at ~/model/Best model/MixResNet18_best_model.pth\n"
     ]
    }
   ],
   "source": [
    "# Lists to store metrics for plotting and analysis\n",
    "all_epochs_train_loss = []\n",
    "all_epochs_train_acc = []\n",
    "all_epochs_val_loss = []\n",
    "all_epochs_val_acc = []\n",
    "epoch_times = []\n",
    "\n",
    "# Instantiate EarlyStopping\n",
    "early_stopping = EarlyStopping(\n",
    "    save_path=MODEL_SAVE_PATH, \n",
    "    patience=EARLY_STOPPING_PATIENCE, \n",
    "    verbose=SHOW_TRAINING_PROCESS:, \n",
    "    delta=EARLY_STOPPING_DELTA\n",
    ")\n",
    "\n",
    "start_time = time()\n",
    "print(\"Starting training...\")\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    epoch_start_time = time()\n",
    "\n",
    "    if SHOW_TRAINING_PROCESS:\n",
    "        print(f\"--- Epoch {epoch+1}/{EPOCH} ---\")\n",
    "        print(f\"Current Learning Rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "    for step, (images, labels) in enumerate(train_dataloader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        prediction = outputs.argmax(dim=1)\n",
    "        train_correct += torch.eq(prediction, labels).sum().item()\n",
    "        train_total += labels.size(0)\n",
    "\n",
    "        if SHOW_TRAINING_PROCESS:\n",
    "            # Progress bar\n",
    "            rate = (step + 1) / len(train_dataloader)\n",
    "            a = \"*\" * int(rate * 50)\n",
    "            b = \".\" * int((1 - rate) * 50)\n",
    "            print(f\"\\rTraining: {int(rate*100):>3d}%[{a}>{b}] Loss: {loss.item():.4f}\", end=\"\")\n",
    "\n",
    "    epoch_train_loss = running_loss / len(train_dataloader)\n",
    "    epoch_train_acc = train_correct / train_total\n",
    "    all_epochs_train_loss.append(epoch_train_loss)\n",
    "    all_epochs_train_acc.append(epoch_train_acc)\n",
    "\n",
    "    # Validation phase\n",
    "    val_acc, val_loss = evaluate(model, val_dataloader, loss_function, device)\n",
    "    all_epochs_val_acc.append(val_acc)\n",
    "    all_epochs_val_loss.append(val_loss)\n",
    "    \n",
    "    scheduler.step(val_acc) # Adjust learning rate based on validation loss\n",
    "    \n",
    "    epoch_end_time = time()\n",
    "    epoch_duration = epoch_end_time - epoch_start_time\n",
    "    epoch_times.append(epoch_duration)\n",
    "\n",
    "    if SHOW_TRAINING_PROCESS:\n",
    "        print(f\"\\nEpoch {epoch+1} Summary | Time: {epoch_duration:.2f}s\")\n",
    "        print(f\"  Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_acc:.4f}\")\n",
    "        print(f\"  Valid Loss: {val_loss:.4f},   Valid Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # Early stopping check\n",
    "    early_stopping(val_acc, model)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping triggered\")\n",
    "        break\n",
    "\n",
    "print(\"\\n--- Training Finished! ---\")\n",
    "total_duration = time() - start_time\n",
    "print(f\"Total training time: {total_duration/60:.2f} minutes\")\n",
    "print(f\"Best model saved at {MODEL_SAVE_PATH}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0287722-5bc7-4cef-b52b-f61fb5230bf7",
   "metadata": {},
   "source": [
    "\n",
    "### 8. Save Results to CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c0415b4-4644-4de6-b608-6b44448b7587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training log saved to ~/model/log/MixResNet18_training_log.csv\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame for the epochs that actually ran\n",
    "completed_epochs = len(all_epochs_train_loss)\n",
    "df = pd.DataFrame({\n",
    "    'epoch': range(1, completed_epochs + 1),\n",
    "    'train_loss': all_epochs_train_loss,\n",
    "    'train_acc': all_epochs_train_acc,\n",
    "    'val_loss': all_epochs_val_loss,\n",
    "    'val_acc': all_epochs_val_acc,\n",
    "    'epoch_duration_s': epoch_times\n",
    "})\n",
    "\n",
    "df.to_csv(CSV_SAVE_PATH, index=False)\n",
    "print(f\"\\nTraining log saved to {CSV_SAVE_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_env]",
   "language": "python",
   "name": "conda-env-pytorch_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
