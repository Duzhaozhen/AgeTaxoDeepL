{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3d45bab-8aca-46d8-b849-1c0c161dfbb0",
   "metadata": {},
   "source": [
    "# ResNet18 Model Tranining Script\n",
    "This Notebook is used to train ResNet18 model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4811fe-3f53-4e32-901f-c86d92a9a0e9",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7322cbae-b67b-41bf-a3a9-d14e6fce0b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torchvision.transforms import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from time import time\n",
    "import json # "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225b2b35-2756-4fff-8e04-add739ce25a7",
   "metadata": {},
   "source": [
    "### 1. Global Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9286575b-b2ab-4d85-9cc6-9b45c78666a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "BATCH_SIZE = 64\n",
    "EPOCH = 40 \n",
    "NUM_CLASSES = 10 # Total number of total categories used for training\n",
    "RANDOM_SEED = 42\n",
    "SHOW_TRAINING_PROCESS = False #Whether to display the training process\n",
    "\n",
    "# Path settings\n",
    "ROOT_DIR = \"/path/to/your/data/folder\" \n",
    "TRAIN_CSV_PATH = os.path.join(ROOT_DIR, \"meta/training_label_info.csv\") # There are two columns, the first is Path and the second is label\n",
    "VAL_CSV_PATH = os.path.join(ROOT_DIR, \"meta/val_label_info.csv\") # There are two columns, the first is Path and the second is label\n",
    "\n",
    "# Path for saving the best model and the results CSV\n",
    "RESULTS_DIR = \"/path/to/your/results/folder\" ### Paths where training set files and validation set files and their images are stored\n",
    "MODEL_SAVE_PATH = os.path.join(RESULTS_DIR, \"ResNet18_best_model.pth\") # model file\n",
    "STATS_SAVE_PATH = os.path.join(RESULTS_DIR, \"ResNet18_normalization_stat.json\") # mean and std\n",
    "CSV_SAVE_PATH = os.path.join(RESULTS_DIR, \"ResNet18_training_log.csv\") ## Training logs with the loss and accuracy of the training and test sets in each epoch\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True) # Ensure the results directory exists\n",
    "\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "\n",
    "# Label and category mapping\n",
    "CUSTOM_LABEL_MAPPING =  {'UniStable': 0, 'UniUnstable': 1,'LinAgeHomo': 2, 'LinAgeHet': 3,'NonAgeHet': 4,\n",
    "                        'Outlier': 5,'TriAge': 6,'TriNonAge': 7,'BiAge':8, 'BiNonAge': 9}\n",
    "\n",
    "CLASSES = tuple(CUSTOM_LABEL_MAPPING.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379486c0-4e92-407c-adf5-818ebd59b855",
   "metadata": {},
   "source": [
    "### 2. Dataset Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e499c77-1874-4fa1-9d50-812df9da15a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CpGImageDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Loads image paths and labels from a CSV file and creates a dataset.\n",
    "    \"\"\"\n",
    "    def __init__(self, root_dir, path_csv, label_mapping, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.path_csv = path_csv\n",
    "        self.transform = transform\n",
    "        self.label_mapping = label_mapping\n",
    "        self.img_info = [] # [(path, label), ... , ]\n",
    "        self._get_img_info()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path_img, label = self.img_info[index]\n",
    "        img = Image.open(path_img).convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        if len(self.img_info) == 0:\n",
    "            raise Exception(\"\\ndata_dir:{} is a empty dir! Please checkout your path to images!\".format(\n",
    "                self.root_dir))  \n",
    "        return len(self.img_info)\n",
    "\n",
    "    def _get_img_info(self):\n",
    "        \"\"\"\n",
    "        Reads the CSV file and parses image paths and labels.\n",
    "        \"\"\"\n",
    "        column_names = [\"Path\",\"Label\"]\n",
    "        df = pd.read_csv(self.path_csv,\n",
    "                header=None, \n",
    "                index_col=False, \n",
    "                names=column_names,\n",
    "                sep=\",\"\n",
    "                )\n",
    "        df.reset_index(inplace=True)\n",
    "\n",
    "        for idx in range(len(df)):\n",
    "            path_img = os.path.join(self.root_dir, df.loc[idx, \"Path\"])\n",
    "            label_str = df.at[idx,\"Label\"]\n",
    "            if label_str in self.label_mapping:\n",
    "                label_int = self.label_mapping[label_str]\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown label on line {idx}: {label_str}\")\n",
    "            self.img_info.append((path_img, label_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fad238-5c04-47e2-b4e2-ab2a60703c0e",
   "metadata": {},
   "source": [
    "### 3. Calculate Mean and Std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faf43dac-baa4-4413-8174-0563dcf83cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing mean and variance for training data...\n",
      "Calculated Mean: [np.float32(0.8576047), np.float32(0.989807), np.float32(0.8576047)]\n",
      "Calculated Std: [np.float32(0.3346952), np.float32(0.039142434), np.float32(0.3346952)]\n",
      "Saving normalization stats at the beginning of the script...\n",
      "Stats saved to: ~/model/ResNet18_normalization_stats.json\n"
     ]
    }
   ],
   "source": [
    "def get_stat(dataset):\n",
    "    \"\"\"\n",
    "    Computes the mean and standard deviation per channel for the dataset.\n",
    "    :param dataset: A PyTorch Dataset object.\n",
    "    :return: (mean, std)\n",
    "    \"\"\"\n",
    "    print('Computing mean and variance for training data...')\n",
    "    loader = DataLoader(dataset, batch_size=1, shuffle=False, pin_memory=True)\n",
    "    \n",
    "    mean = torch.zeros(3)\n",
    "    std = torch.zeros(3)\n",
    "    for x,_ in loader:\n",
    "        for d in range(3):\n",
    "            mean[d]+= x[:,d,:,:].mean()\n",
    "            std[d] += x[:,d,:,:].std()\n",
    "    mean.div_(len(dataset))\n",
    "    std.div_(len(dataset))\n",
    "    return list(mean.numpy()), list(std.numpy())\n",
    "    \n",
    "    return mean.tolist(), std.tolist()\n",
    "\n",
    "# Step 3.1: Create a temporary dataset with only ToTensor transformation to calculate stats\n",
    "temp_transform = transforms.Compose([transforms.ToTensor()])\n",
    "stat_dataset = CpGImageDataset(ROOT_DIR, TRAIN_CSV_PATH, CUSTOM_LABEL_MAPPING, transform=temp_transform)\n",
    "# Step 3.2: Calculate the mean and std\n",
    "mean, std = get_stat(stat_dataset)\n",
    "print(f\"Calculated Mean: {mean}\")\n",
    "print(f\"Calculated Std: {std}\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"Saving normalization stats at the beginning of the script...\")\n",
    "norm_stats = {\n",
    "    'mean': [float(x) for x in mean],\n",
    "    'std': [float(x) for x in std]\n",
    "}\n",
    "with open(STATS_SAVE_PATH, 'w') as f:\n",
    "    json.dump(norm_stats, f, indent=4)\n",
    "print(f\"Stats saved to: {STATS_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a68505-82f9-4c53-845c-f0960df3a85c",
   "metadata": {},
   "source": [
    "### 4. Data Preprocessing and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f943d4e7-3a0a-459e-b587-fdd6becdb1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 8000\n",
      "Number of validation samples: 2000\n"
     ]
    }
   ],
   "source": [
    "# Define data transformations using the calculated mean and std\n",
    "data_transform = {\n",
    "    \"train\": transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ]),\n",
    "    \"val\": transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Create the final training and validation datasets\n",
    "train_data = CpGImageDataset(ROOT_DIR, TRAIN_CSV_PATH, CUSTOM_LABEL_MAPPING, transform=data_transform[\"train\"])\n",
    "val_data = CpGImageDataset(ROOT_DIR, VAL_CSV_PATH, CUSTOM_LABEL_MAPPING, transform=data_transform[\"val\"])\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "val_dataloader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"Number of training samples: {len(train_data)}\")\n",
    "print(f\"Number of validation samples: {len(val_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7dbd768-511a-4971-b3f7-538781eea33c",
   "metadata": {},
   "source": [
    "### 5. Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3da62b6e-c756-47b5-804e-15acab4b5ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet18(num_classes):\n",
    "    \"\"\"\n",
    "    Loads the ResNet18 model and adapts its fully connected layer \n",
    "    to the specified number of classes.\n",
    "    \"\"\"\n",
    "    res18 = models.resnet18(weights=None) # Train from scratch, not using pre-trained weights\n",
    "    num_ftrs = res18.fc.in_features\n",
    "    res18.fc = nn.Linear(num_ftrs, num_classes)\n",
    "    return res18\n",
    "\n",
    "# Instantiate the model and move it to the specified device\n",
    "model = ResNet18(num_classes=NUM_CLASSES).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.1, patience=3)\n",
    "loss_function = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed8c6b0-3507-478f-8700-9cac073bf120",
   "metadata": {},
   "source": [
    "### 6. Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21faabac-31b3-451b-8c4d-577a2d540781",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, loss_fn, device):\n",
    "    \"\"\"Evaluates the model on a given dataset.\"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():  # No need to track gradients for evaluation\n",
    "        for images, labels in data_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            prediction = outputs.argmax(dim=1)\n",
    "            correct_predictions += torch.eq(prediction, labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "            \n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    accuracy = correct_predictions / total_samples\n",
    "    return accuracy, avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaddd5f-175f-43eb-9f85-4a4653be8eff",
   "metadata": {},
   "source": [
    "### 7. Training and Validation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e8d3437-c4a1-4aa6-b736-a219ca0ccb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "\n",
      "--- Training Finished! ---\n",
      "Total training time: 10.81 minutes\n",
      "Best validation accuracy: 0.8265 at epoch 39\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Lists to store metrics for plotting and analysis\n",
    "all_epochs_train_loss = []\n",
    "all_epochs_train_acc = []\n",
    "all_epochs_val_loss = []\n",
    "all_epochs_val_acc = []\n",
    "epoch_times = []\n",
    "\n",
    "best_acc, best_epoch = 0.0, 0\n",
    "start_time = time()\n",
    "print(\"Starting training...\")\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    epoch_start_time = time()\n",
    "\n",
    "    if SHOW_TRAINING_PROCESS:\n",
    "        print(f\"--- Epoch {epoch+1}/{EPOCH} ---\")\n",
    "        print(f\"Current Learning Rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "    for step, (images, labels) in enumerate(train_dataloader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        prediction = outputs.argmax(dim=1)\n",
    "        train_correct += torch.eq(prediction, labels).sum().item()\n",
    "        train_total += labels.size(0)\n",
    "\n",
    "        if SHOW_TRAINING_PROCESS:\n",
    "            # Progress bar\n",
    "            rate = (step + 1) / len(train_dataloader)\n",
    "            a = \"=\" * int(rate * 40)\n",
    "            b = \".\" * int((1 - rate) * 40)\n",
    "            print(f\"\\rTraining: {int(rate*100):>3d}% [{a}>{b}] Loss: {loss.item():.4f}\", end=\"\")\n",
    "\n",
    "    epoch_train_loss = running_loss / len(train_dataloader)\n",
    "    epoch_train_acc = train_correct / train_total\n",
    "    all_epochs_train_loss.append(epoch_train_loss)\n",
    "    all_epochs_train_acc.append(epoch_train_acc)\n",
    "\n",
    "    # Validation phase\n",
    "    val_acc, val_loss = evaluate(model, val_dataloader, loss_function, device)\n",
    "    all_epochs_val_acc.append(val_acc)\n",
    "    all_epochs_val_loss.append(val_loss)\n",
    "    \n",
    "    scheduler.step(val_loss) # Adjust learning rate based on validation loss\n",
    "    \n",
    "    epoch_end_time = time()\n",
    "    epoch_duration = epoch_end_time - epoch_start_time\n",
    "    epoch_times.append(epoch_duration)\n",
    "    \n",
    "    if SHOW_TRAINING_PROCESS:\n",
    "        print(f\"\\nEpoch {epoch+1} Summary | Time: {epoch_duration:.2f}s\")\n",
    "        print(f\"  Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_acc:.4f}\")\n",
    "        print(f\"  Valid Loss: {val_loss:.4f}, Valid Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # Save the best model\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        best_epoch = epoch + 1\n",
    "      \n",
    "        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "        if SHOW_TRAINING_PROCESS:\n",
    "            print(f\"New best model saved! Accuracy: {best_acc:.4f} at epoch {best_epoch}\")\n",
    "\n",
    "print(\"\\n--- Training Finished! ---\")\n",
    "total_duration = time() - start_time\n",
    "print(f\"Total training time: {total_duration/60:.2f} minutes\")\n",
    "print(f\"Best validation accuracy: {best_acc:.4f} at epoch {best_epoch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3011da7e-18c8-4dcc-a874-acf5724f833b",
   "metadata": {},
   "source": [
    "### 8. Save Results to CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0507105-85ed-4192-81bc-6cf235df4211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training log saved to ~/model/log/ResNet18_training_log.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.DataFrame({\n",
    "    'epoch': range(1, EPOCH + 1),\n",
    "    'train_loss': all_epochs_train_loss,\n",
    "    'train_acc': all_epochs_train_acc,\n",
    "    'val_loss': all_epochs_val_loss,\n",
    "    'val_acc': all_epochs_val_acc,\n",
    "    'epoch_duration_s': epoch_times\n",
    "})\n",
    "\n",
    "\n",
    "df.to_csv(CSV_SAVE_PATH, index=False)\n",
    "print(f\"\\nTraining log saved to {CSV_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2d947a-1f61-483e-ad10-d4d5c7a0e283",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_env]",
   "language": "python",
   "name": "conda-env-pytorch_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
